{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1ME8m2EE3c4"
   },
   "source": [
    "# Agentic RAG in LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M4zgrIYtzEW"
   },
   "source": [
    "## Part 0: Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "id": "gpk5DaC8E3c9",
    "outputId": "dc5d5c8b-538c-408f-fd63-5079a7f76271"
   },
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vobdEXgquH-I"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QysSnlVpE3c-"
   },
   "source": [
    "And, let's log in to Hugging Face to use serverless Inference APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz3QdNYCtU7u"
   },
   "source": [
    "## Part 1: Simple RAG Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUJReWButXJp",
    "outputId": "6b6642ac-6eb0-4d95-b75a-483852b54f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 document(s).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Load document\n",
    "reader = SimpleDirectoryReader(input_files=[\"Zeolite.pdf\"])\n",
    "documents = reader.load_data()\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "\n",
    "# Split into chunks\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "# Set up LLM and embedding model\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Create vector index\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "\n",
    "# Create query engine\n",
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNDjd6WKAiGU"
   },
   "source": [
    "#### 1.1 Inspecting the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iipL_cCRAhAf",
    "outputId": "5593d075-db9f-44a0-b0b7-08575976ebe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 8\n",
      "Number of node references: 8\n",
      "\n",
      "--- Embedding 0 ---\n",
      "Node ID: c71af4d9-8bb4-47f4-99ad-7b2e21997abf\n",
      "Embedding dimension: 1536\n",
      "First 10 values: [-0.017029738053679466, 0.016129735857248306, -0.013598478399217129, -0.0037757924292236567, 0.0010836946312338114, 0.0394313670694828, -0.030853217467665672, -0.022176628932356834, -0.021206313744187355, -0.031106343492865562]\n",
      "\n",
      "--- Embedding 1 ---\n",
      "Node ID: 6c65adf5-df60-42e3-9122-1570dceb7c62\n",
      "Embedding dimension: 1536\n",
      "First 10 values: [-0.012685132212936878, 0.021696804091334343, -0.017266638576984406, -0.0001718709827400744, -0.0031076509039849043, 0.03711983188986778, -0.025659188628196716, -0.013242342509329319, -0.010112334042787552, -0.030378276482224464]\n",
      "\n",
      "--- Embedding 2 ---\n",
      "Node ID: 949cbf35-5bf2-42cf-a707-e4d33f673ece\n",
      "Embedding dimension: 1536\n",
      "First 10 values: [-0.01880381442606449, 0.01112142950296402, -0.018415534868836403, -0.005844990722835064, -0.005654317792505026, 0.035167016088962555, -0.039881836622953415, -0.026361392810940742, -0.016585074365139008, -0.016945619136095047]\n"
     ]
    }
   ],
   "source": [
    "# Access the vector store data directly\n",
    "vector_store = vector_index.vector_store\n",
    "\n",
    "# Get embedding dictionary and node dictionary\n",
    "embedding_dict = vector_store.data.embedding_dict\n",
    "node_dict = vector_store.data.text_id_to_ref_doc_id\n",
    "\n",
    "print(f\"Number of embeddings: {len(embedding_dict)}\")\n",
    "print(f\"Number of node references: {len(node_dict)}\")\n",
    "\n",
    "# Show first few embeddings\n",
    "for i, (node_id, embedding) in enumerate(list(embedding_dict.items())[:3]):\n",
    "    print(f\"\\n--- Embedding {i} ---\")\n",
    "    print(f\"Node ID: {node_id}\")\n",
    "    print(f\"Embedding dimension: {len(embedding)}\")\n",
    "    print(f\"First 10 values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6caODl2LAkuf"
   },
   "source": [
    "#### 1.2 Asking questions to the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQwyzi6StoOE",
    "outputId": "9b7f31d0-4017-47dc-b834-49c4f084fcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desensitization refers to the reduction of the sensitivity of energetic materials, aiming to make them safer to handle and use. This process is crucial for enhancing safety in various applications, such as the production of standards for analytical purposes and the detection of explosive devices.\n"
     ]
    }
   ],
   "source": [
    "# Query the document\n",
    "response = query_engine.query(\"What is Desensitization?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FrcVI5_AoKj"
   },
   "source": [
    "#### 1.3 Checking if the responses make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzWW3i6d--cv",
    "outputId": "492d209e-bbdc-4fba-8aab-d42c4535d8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSUGVGT1ACSL",
    "outputId": "66dfbb46-fbde-4a93-dd2a-8ceb4fbd6cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes:\n",
      "==================================================\n",
      "Node 1:\n",
      "Score: 0.7888532040805272\n",
      "Text: DOI: 10.1002/adma.200601109\n",
      "High-Density Energetic Material Hosted in Pure Silica MFI-T ype\n",
      "Zeolite Nanocrystals**\n",
      "By Gerardo Majano, Svetlana Mintova ,* Thomas Bein , and Thomas M. Klapötke *\n",
      "Desensitization, that is, the reduction of the sensitivity of\n",
      "energetic materials, has been an essential subject of interest\n",
      "since the discovery of energetic materials and continues to be\n",
      "important nowadays . Prime examples of such materials are\n",
      "black powder and dynamite, which are desensitized potassium\n",
      "nitrate and nitroglycerine, respectively . Thus , desensitizing\n",
      "these compounds is of great importance not only to enhance\n",
      "their safe use, but also to make them less dangerous in fields\n",
      "such as the production of standards for analytical purposes\n",
      "and the detection of explosive devices.\n",
      "[1–3] Ideally , the desensi-\n",
      "tized energetic materials, depending on their intended use,\n",
      "should possess properties similar to those of the pure com-\n",
      "pound, including spectral and thermal properties , while avoid-\n",
      "ing hazards such as friction, heat, and shock sensitivity .\n",
      "[4]\n",
      "One of the traditional ways to desensitize crystalline high-\n",
      "energy materials is to press and knead them into a form with\n",
      "the help of binders and plasticizers to shape plastically\n",
      "bonded explosives.\n",
      "[5] Other procedures include mixing the en-\n",
      "ergetic materials with inert substances such as salts or oil, [6,7]\n",
      "or coating with waxes or plasticizers,[8,9] and additionally regu-\n",
      "lating the oxygen balance with the help of nonexplosive nitro-\n",
      "compounds .\n",
      "[10] However, these procedures sometimes cause\n",
      "problems at different stages of the manufacturing process , for\n",
      "instance during dry mixing or blending at elevated tempera-\n",
      "tures . Furthermore, some of the additives for desensitizing/\n",
      "plasticizing also raise environmental concerns and increase\n",
      "the cost considerably . Thus developing a safe, cost-effective,\n",
      "and environmentally friendly way to desensitize crystalline\n",
      "highly energetic materials is of great interest. Besides , there is\n",
      "an escalating need for detection of sensitive energetic materi-\n",
      "als used in improvised explosive devices with safety issues as\n",
      "the main concern.\n",
      "Inclusion chemistry in framework-type materials has shown\n",
      "an effective tailoring of some of the physicochemical proper -\n",
      "ties of molecules and compounds through orientation and/or\n",
      "conformation inside the porous networks .\n",
      "[11] The incorporated\n",
      "materials usually exhibit properties that differ from those in\n",
      "the pure solid or solution phases; they may even display some\n",
      "properties that cannot be achieved in either of these, such as\n",
      "nonlinear optical responses for second-harmonic generation\n",
      "and micro-antenna applications.\n",
      "[12,13] For inclusion chemistry ,\n",
      "the unique pore structure of crystalline zeolite-type materials\n",
      "based on tetrahedrally coordinated silicon and aluminum is\n",
      "very attractive. These materials offer large pore volume and\n",
      "great internal and external surface areas with variable pore\n",
      "openings and apertures . Such structures make it possible for\n",
      "so-called guest molecules, either neutral or charged, to pene-\n",
      "trate and leave the porous structure by diffusion processes .\n",
      "The lifetime of various labile species and molecules incor-\n",
      "porated in zeolites has been described in the open litera-\n",
      "ture,\n",
      "[14] but not the thermal decomposition, which in the case\n",
      "of high-energy materials is of extreme importance. The use of\n",
      "zeolites in connection with high-density energetic materials to\n",
      "date has been restricted to vague ways to reduce the toxicity\n",
      "of the gases produced upon decomposition,\n",
      "[15] and as a filling\n",
      "material for mixtures of nitrates .[16]\n",
      "The objective of the work reported here is to apply nano-\n",
      "meter-sized microporous crystals with a regular pore system\n",
      "to immobilize high-density energetic materials, and to demon-\n",
      "strate the stabilization role of the porous host in the prepara-\n",
      "tion of safe standards for diverse detection purposes . More-\n",
      "over, it is important to note that all the desensitizing\n",
      "procedures for energetic materials reported up to now are not\n",
      "aimed at detection purposes . The system presented here al-\n",
      "lows not only the stabilization of highly energetic compounds ,\n",
      "but also the creation of standards for possible identification\n",
      "based on spectroscopic techniques .\n",
      "For the current study , a pure silica zeolite with MFI-type\n",
      "structure with nanometer -sized dimensions was chosen in or -\n",
      "der to achieve high loading with the energetic material\n",
      "through fast diffusion, and to keep some remaining vapor\n",
      "pressure for further investigations on other compounds that\n",
      "rely heavily on it for their detection through dogs and spec-\n",
      "trometry techniques .\n",
      "Metadata: {'page_label': '0', 'file_name': 'Zeolite.pdf', 'file_path': 'Zeolite.pdf', 'file_type': 'application/pdf', 'file_size': 205139, 'creation_date': '2025-07-05', 'last_modified_date': '2025-07-05'}\n",
      "------------------------------\n",
      "Node 2:\n",
      "Score: 0.7484434529985383\n",
      "Text: More-\n",
      "over, it is important to note that all the desensitizing\n",
      "procedures for energetic materials reported up to now are not\n",
      "aimed at detection purposes . The system presented here al-\n",
      "lows not only the stabilization of highly energetic compounds ,\n",
      "but also the creation of standards for possible identification\n",
      "based on spectroscopic techniques .\n",
      "For the current study , a pure silica zeolite with MFI-type\n",
      "structure with nanometer -sized dimensions was chosen in or -\n",
      "der to achieve high loading with the energetic material\n",
      "through fast diffusion, and to keep some remaining vapor\n",
      "pressure for further investigations on other compounds that\n",
      "rely heavily on it for their detection through dogs and spec-\n",
      "trometry techniques .\n",
      "[1–3] It is anticipated that the MFI zeolite\n",
      "with its three-dimensional channel network will be able to in-\n",
      "clude high-energy materials and separate them into localized\n",
      "domains , and thus will delay or hinder a chain reaction that\n",
      "would eventually lead to an explosion. Also, the MFI net-\n",
      "work, consisting of intersecting straight and sinusoidal chan-\n",
      "nels occupied by the energetic materials, would be able to\n",
      "control an exothermic reaction in a way that the net local\n",
      "COMMUNICATIONS\n",
      "2440\n",
      " © 2006 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim Adv . Mater.2006, 18, 2440–2443\n",
      "–\n",
      "[*] Dr . S. Mintova, G. Majano\n",
      "Laboratoire de Matériaux à Porosité Contrôlée, UMR-7016 CNRS\n",
      "68093 Mulhouse (France)\n",
      "E-mail: Svetlana.Mintova@univ-mulhouse.fr\n",
      "Prof. T . M. Klapötke, Prof. T . Bein\n",
      "Department of Chemistry and Biochemistry , University of Munich\n",
      "81377 Munich (Germany)\n",
      "E-mail: Thomas.M.Klapoetke@cup.uni-muenchen.de\n",
      "[**] Support by PROCOPE, the Fonds der Chemischen Industrie, the\n",
      "European Research Office of the US ARL (N62558-05-C-0027), and\n",
      "the Bundeswehr Research Institute for Materials (E/E210/4D004/\n",
      "X5143) is gratefully acknowledged.\n",
      "Metadata: {'page_label': '0', 'file_name': 'Zeolite.pdf', 'file_path': 'Zeolite.pdf', 'file_type': 'application/pdf', 'file_size': 205139, 'creation_date': '2025-07-05', 'last_modified_date': '2025-07-05'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print out each source node\n",
    "print(\"Source nodes:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, node in enumerate(response.source_nodes):\n",
    "    print(f\"Node {i+1}:\")\n",
    "    print(f\"Score: {node.score}\")\n",
    "    print(f\"Text: {node.text}\")\n",
    "    print(f\"Metadata: {node.metadata}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I59dl1cstpOY",
    "outputId": "7825d4bc-ea61-49f6-e6fe-edd7a341dc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nanometer-sized MFI-type zeolite was synthesized from pure silica solutions with a composition of 25 SiO2:9 TPAOH:420 H2O:100 EtOH. The clear solution was converted into a crystalline suspension by heating at 90 °C for 4 days.\n"
     ]
    }
   ],
   "source": [
    "# Ask more questions\n",
    "response2 = query_engine.query(\"How was Nanometer-sized MFI-type zeolite synthesized?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pu_T0jLStqU-",
    "outputId": "1d38f476-9922-48b3-cdc6-3134a482be2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses how MFI zeolites can be used to stabilize highly energetic compounds, create standards for identification based on spectroscopic techniques, include high-energy materials in localized domains to prevent explosions, control exothermic reactions, and immobilize energetic materials like Fox-7 for thermal stabilization and safe handling. Additionally, MFI zeolites provide low spectral profiles in techniques such as Raman, 13C NMR, and mass spectrometry, making them ideal for detecting explosives in post-explosion debris.\n"
     ]
    }
   ],
   "source": [
    "response3 = query_engine.query(\"What does the document say MFI zeolites?\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1T80meUE3dA"
   },
   "source": [
    "## Part 2: Agentic RAG\n",
    "\n",
    "Let's now upgrade the previously defined RAG system into an Agentic RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsJGdIJ3afAH",
    "outputId": "269bee18-f692-41bb-c6f9-8f1393d8fd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (0.33.2)\n",
      "Requirement already satisfied: packaging in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Installing collected packages: fsspec, dill, multiprocess, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [datasets]3/4\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16\n",
      "Requirement already satisfied: huggingface-hub in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (0.33.2)\n",
      "Requirement already satisfied: filelock in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from huggingface-hub) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests->huggingface-hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests->huggingface-hub) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets\n",
    "!pip install --upgrade huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAHJ_2iLt-gH"
   },
   "source": [
    "#### 2.1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ju5oAHyNX7du",
    "outputId": "20af0139-6619-4d62-9ad5-2eeaecddc525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 document(s).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"Zeolite.pdf\"])\n",
    "documents = reader.load_data()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HWY21vPuBdw"
   },
   "source": [
    "#### 2.2: Breaking the data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "maOPpR4iis3M"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# chunk_size of 1024 is a good default value\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "# Create nodes from documents\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJnGnuAZuKzD"
   },
   "source": [
    "#### 2.3 Define the LLM and the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3DCnVNCFizXV"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# LLM model\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "# embedding model\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZkCDa6UuOgi"
   },
   "source": [
    "#### 2.4 Create the vector index and summary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aBu3TAWni2Vy"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "# summary index\n",
    "summary_index = SummaryIndex(nodes)\n",
    "# vector store index\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOUKB4heuSO_"
   },
   "source": [
    "#### 2.4 Create the vector query engine and summary query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9l9lVrgNi6Dd"
   },
   "outputs": [],
   "source": [
    "# summary query engine\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "# vector query engine\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEpulllzuWHI"
   },
   "source": [
    "#### 2.5 Convert the vector and query engines into tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UHugM5x-i8Bf"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to the State of MFI Zeolite.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the the State of MFI Zeolite.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYhHCqoLucC7"
   },
   "source": [
    "#### 2.6 Define a superset query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LF3YTqDli-FR"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKbSL_tbuflQ"
   },
   "source": [
    "#### 2.7 Test whether the query engine works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAA2JIhai_n_",
    "outputId": "446b5976-b6d3-42a0-d40a-10e80c30c241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking for a specific method of synthesis, which falls under retrieving specific context from the State of MFI Zeolite..\n",
      "\u001b[0mNanometer-sized MFI-type zeolite was synthesized from pure silica solutions with a composition of 25 SiO2 : 9 TPAOH : 420 H2O : 100 EtOH. The clear solution was converted into a crystalline suspension by heating at 90 °C for 4 days.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How was Nanometer-sized MFI-type zeolite synthesized?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjBMU8pwul8P"
   },
   "source": [
    "#### 2.8 Convert the query engine into a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-xAHwfwqulcO"
   },
   "outputs": [],
   "source": [
    "# Create tool wrapper around router\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"state_of_zeolites_report_assistant\",\n",
    "    description=\"Answers questions based on zeolite.\",\n",
    "    return_direct=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcy5m7bYuokd"
   },
   "source": [
    "#### 2.9 Define system prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "adx0Y8UgmJHu"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant specialized in answering questions using the research paper provided.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Use the Summary Tool when the user asks for high-level insights, main contributions, methodology overview, results summary, or general understanding \n",
    "   (e.g., \"What are the key findings of this paper?\" or \"Summarize the methodology and contributions.\").\n",
    "\n",
    "2. Use the Vector Tool when the user asks for specific statistics, experiment results, detailed explanations of methods, or references to figures/tables in the paper\n",
    "   (e.g., \"What is the model’s accuracy on the benchmark dataset?\" or \"Explain the optimization technique used in Section 3.\").\n",
    "\n",
    "Refer only to the content of the paper. If the user's query is outside this context, politely decline or redirect.\n",
    "\n",
    "Check your answer multiple times to ensure it is accurate and explicitly mentioned in the paper.\n",
    "\n",
    "Examples of summary queries:\n",
    "- \"Summarize the paper's proposed approach.\"\n",
    "- \"What problem does this paper address?\"\n",
    "\n",
    "Examples of specific/vector queries:\n",
    "- \"What is the performance improvement over baseline methods?\"\n",
    "- \"What dataset was used for evaluation?\"\n",
    "\n",
    "Always explain clearly, referencing exact statistics, sections, figures, or methods when relevant. Be concise and insightful.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7xhEtfvut_s"
   },
   "source": [
    "#### 2.10 Define the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bt-1Pnr7jMfK"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=Settings.llm,\n",
    "    system_prompt=system_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFUqiH8kE3dB"
   },
   "source": [
    "#### 2.11 Setup agent observability using Arize Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CRE0SnzJeY47",
    "outputId": "a8a23cad-00df-4b4c-b021-66e3f5d63fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-callbacks-arize-phoenix\n",
      "  Downloading llama_index_callbacks_arize_phoenix-0.5.1-py3-none-any.whl.metadata (744 bytes)\n",
      "Collecting arize-phoenix\n",
      "  Downloading arize_phoenix-11.4.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-callbacks-arize-phoenix) (0.12.46)\n",
      "Collecting openinference-instrumentation-llama-index>=4.1.0 (from llama-index-callbacks-arize-phoenix)\n",
      "  Downloading openinference_instrumentation_llama_index-4.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2025.3.0)\n",
      "Requirement already satisfied: httpx in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (11.3.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.20.1)\n",
      "Requirement already satisfied: griffe in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.10)\n",
      "Collecting aioitertools (from arize-phoenix)\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: alembic<2,>=1.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.16.2)\n",
      "Collecting arize-phoenix-client (from arize-phoenix)\n",
      "  Downloading arize_phoenix_client-1.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting arize-phoenix-evals>=0.20.6 (from arize-phoenix)\n",
      "  Downloading arize_phoenix_evals-0.22.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting arize-phoenix-otel>=0.10.3 (from arize-phoenix)\n",
      "  Downloading arize_phoenix_otel-0.12.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting authlib (from arize-phoenix)\n",
      "  Downloading authlib-1.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: cachetools in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (5.5.2)\n",
      "Collecting email-validator (from arize-phoenix)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: fastapi in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (0.115.14)\n",
      "Collecting grpc-interceptor (from arize-phoenix)\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: grpcio in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.73.1)\n",
      "Collecting openinference-instrumentation>=0.1.32 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation-0.1.34-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.20 (from arize-phoenix)\n",
      "  Downloading openinference_semantic_conventions-0.1.21-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (0.55b1)\n",
      "Requirement already satisfied: pandas>=1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (2.2.3)\n",
      "Requirement already satisfied: protobuf<6.0,>=4.25.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (5.29.5)\n",
      "Requirement already satisfied: psutil in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (7.0.0)\n",
      "Requirement already satisfied: pyarrow in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (2.9.0.post0)\n",
      "Requirement already satisfied: python-multipart in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (0.0.20)\n",
      "Requirement already satisfied: scikit-learn in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.7.0)\n",
      "Requirement already satisfied: scipy in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (1.15.3)\n",
      "Collecting sqlean-py>=3.45.1 (from arize-phoenix)\n",
      "  Downloading sqlean_py-3.49.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: starlette in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (0.46.2)\n",
      "Collecting strawberry-graphql==0.270.1 (from arize-phoenix)\n",
      "  Downloading strawberry_graphql-0.270.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: uvicorn in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arize-phoenix) (0.35.0)\n",
      "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.270.1->arize-phoenix)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=23 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from strawberry-graphql==0.270.1->arize-phoenix) (24.2)\n",
      "Requirement already satisfied: Mako in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.3.10)\n",
      "Requirement already satisfied: tomli in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from alembic<2,>=1.3.0->arize-phoenix) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from python-dateutil->arize-phoenix) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.2.3)\n",
      "Requirement already satisfied: click in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2024.11.6)\n",
      "Requirement already satisfied: opentelemetry-api in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from openinference-instrumentation>=0.1.32->arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from openinference-instrumentation-llama-index>=4.1.0->llama-index-callbacks-arize-phoenix) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (2025.6.15)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.1.0)\n",
      "Requirement already satisfied: cryptography in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from authlib->arize-phoenix) (45.0.5)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from cffi>=1.14->cryptography->authlib->arize-phoenix) (2.22)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.26.1)\n",
      "Collecting dnspython>=2.0.0 (from email-validator->arize-phoenix)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from starlette->arize-phoenix) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette->arize-phoenix) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette->arize-phoenix) (1.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-callbacks-arize-phoenix) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from opentelemetry-api->openinference-instrumentation>=0.1.32->arize-phoenix) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation>=0.1.32->arize-phoenix) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.34.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.34.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp->arize-phoenix) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp->arize-phoenix) (1.34.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
      "Downloading llama_index_callbacks_arize_phoenix-0.5.1-py3-none-any.whl (3.1 kB)\n",
      "Downloading arize_phoenix-11.4.0-py3-none-any.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading strawberry_graphql-0.270.1-py3-none-any.whl (301 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading arize_phoenix_evals-0.22.0-py3-none-any.whl (64 kB)\n",
      "Downloading arize_phoenix_otel-0.12.1-py3-none-any.whl (13 kB)\n",
      "Downloading openinference_instrumentation-0.1.34-py3-none-any.whl (28 kB)\n",
      "Downloading openinference_instrumentation_llama_index-4.3.1-py3-none-any.whl (28 kB)\n",
      "Downloading openinference_semantic_conventions-0.1.21-py3-none-any.whl (10 kB)\n",
      "Downloading sqlean_py-3.49.1-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Downloading arize_phoenix_client-1.12.0-py3-none-any.whl (65 kB)\n",
      "Downloading authlib-1.6.0-py2.py3-none-any.whl (239 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: sqlean-py, openinference-semantic-conventions, grpc-interceptor, graphql-core, dnspython, aioitertools, strawberry-graphql, email-validator, authlib, arize-phoenix-evals, arize-phoenix-client, openinference-instrumentation, openinference-instrumentation-llama-index, llama-index-callbacks-arize-phoenix, arize-phoenix-otel, arize-phoenix\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [arize-phoenix]0m [arize-phoenix]client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aioitertools-0.12.0 arize-phoenix-11.4.0 arize-phoenix-client-1.12.0 arize-phoenix-evals-0.22.0 arize-phoenix-otel-0.12.1 authlib-1.6.0 dnspython-2.7.0 email-validator-2.2.0 graphql-core-3.2.6 grpc-interceptor-0.15.4 llama-index-callbacks-arize-phoenix-0.5.1 openinference-instrumentation-0.1.34 openinference-instrumentation-llama-index-4.3.1 openinference-semantic-conventions-0.1.21 sqlean-py-3.49.1 strawberry-graphql-0.270.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-callbacks-arize-phoenix arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0jSmLawdeTEN"
   },
   "outputs": [],
   "source": [
    "import llama_index\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = \"\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "434C1PNgu2YT"
   },
   "source": [
    "#### 2.12 Run the agent and analyze responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxC0y5llE3dB",
    "outputId": "f5a5ba5b-3d1b-430c-ff5b-20f2ba0844c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Useful for retrieving specific context from the State of MFI Zeolite..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses the successful immobilization of a high-density energetic material (Fox-7) inside nanometer-sized zeolites of the MFI type. This immobilization stabilizes Fox-7, preventing explosive decomposition at lower temperatures and offering new possibilities for safe standard materials for detection. The nanometer-sized zeolite hosts provide thermal and mechanical stability, making them ideal for detecting highly sensitive guest molecules.\n"
     ]
    }
   ],
   "source": [
    "# In Jupyter/Colab, you can use await directly\n",
    "question = \"Who did the document say about zeolite\"\n",
    "response = await query_engine_agent.run(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PxekjRYu5HV"
   },
   "source": [
    "#### 2.13 Equip the agent with multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1fkBji-joOLP",
    "outputId": "50fac1d7-7f1b-4f18-e627-a5621fba50b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-tools-arxiv\n",
      "  Downloading llama_index_tools_arxiv-0.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting llama-index-tools-wikipedia\n",
      "  Downloading llama_index_tools_wikipedia-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.0.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting arxiv<3.0.0,>=2.1.0 (from llama-index-tools-arxiv)\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-tools-arxiv) (0.12.46)\n",
      "Collecting feedparser~=6.0.10 (from arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2.32.4)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp<4,>=3.8.6 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2025.3.0)\n",
      "Requirement already satisfied: httpx in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (11.3.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (6.0.2)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.20.1)\n",
      "Requirement already satisfied: griffe in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2025.6.15)\n",
      "Collecting wikipedia<2.0,>=1.4 (from llama-index-tools-wikipedia)\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from wikipedia<2.0,>=1.4->llama-index-tools-wikipedia) (4.13.4)\n",
      "Requirement already satisfied: click>=8.1.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from duckduckgo-search) (8.2.1)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: joblib in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from beautifulsoup4->wikipedia<2.0,>=1.4->llama-index-tools-wikipedia) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.4.6)\n",
      "Requirement already satisfied: anyio in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.0.2)\n",
      "Downloading llama_index_tools_arxiv-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading llama_index_tools_wikipedia-0.3.0-py3-none-any.whl (2.7 kB)\n",
      "Downloading duckduckgo_search-8.0.5-py3-none-any.whl (18 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-macosx_10_9_universal2.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m806.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m630.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: wikipedia, sgmllib3k\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11757 sha256=feaca4998784aad174c477f62ed5a8ea9b971dc977a88319d12c90e84d1dddd4\n",
      "  Stored in directory: /Users/eolanrew/Library/Caches/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "\u001b[33m  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=89a641ca3ca48776f61a4ef61054638dcca2b6a7f524a7e94067cab5c68ef14d\n",
      "  Stored in directory: /Users/eolanrew/Library/Caches/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built wikipedia sgmllib3k\n",
      "Installing collected packages: sgmllib3k, primp, lxml, feedparser, wikipedia, duckduckgo-search, arxiv, llama-index-tools-wikipedia, llama-index-tools-arxiv\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [llama-index-tools-arxiv]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arxiv-2.2.0 duckduckgo-search-8.0.5 feedparser-6.0.11 llama-index-tools-arxiv-0.3.0 llama-index-tools-wikipedia-0.3.0 lxml-6.0.0 primp-0.15.0 sgmllib3k-1.0.0 wikipedia-1.4.0\n",
      "Collecting llama-index-tools-brave-search\n",
      "  Downloading llama_index_tools_brave_search-0.3.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-tools-brave-search) (0.12.46)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2025.3.0)\n",
      "Requirement already satisfied: httpx in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (11.3.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.20.1)\n",
      "Requirement already satisfied: griffe in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.10)\n",
      "Requirement already satisfied: click in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.4.6)\n",
      "Requirement already satisfied: anyio in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/eolanrew/miniconda3/envs/code-demo-env/envs/exercise/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.0.2)\n",
      "Downloading llama_index_tools_brave_search-0.3.0-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: llama-index-tools-brave-search\n",
      "Successfully installed llama-index-tools-brave-search-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-tools-arxiv llama-index-tools-wikipedia duckduckgo-search\n",
    "!pip install llama-index-tools-brave-search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16E17tfjvLIx"
   },
   "source": [
    "#### 2.14 Add the new tools (ArXiV, Brave Search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "soxyYOVfoAHB"
   },
   "outputs": [],
   "source": [
    "# Import additional tools\n",
    "from llama_index.tools.arxiv import ArxivToolSpec\n",
    "from llama_index.tools.wikipedia import WikipediaToolSpec\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.tools.brave_search import BraveSearchToolSpec\n",
    "\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "m2lC5H1SoYpm"
   },
   "outputs": [],
   "source": [
    "# Create ArXiV tool\n",
    "\n",
    "arxiv_tool = ArxivToolSpec()\n",
    "\n",
    "arxiv_tools = arxiv_tool.to_tool_list()\n",
    "\n",
    "\n",
    "# Create Brave Search tool\n",
    "\n",
    "brave_search_tool_spec = BraveSearchToolSpec(api_key=\"\")\n",
    "brave_search_tools = brave_search_tool_spec.to_tool_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Rp0WSiqpodii"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create enhanced agent with multiple tools - FIX: Use extend instead of append\n",
    "enhanced_tools = [query_engine_tool]  # Start with McKinsey report tool\n",
    "enhanced_tools.extend(brave_search_tools)  # Add all brave search tools\n",
    "enhanced_tools.extend(arxiv_tools)  # Add all arxiv tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjWiEqbHvSmE"
   },
   "source": [
    "#### 2.15 Define the enhanced agent with all tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QFaTmUITooBF"
   },
   "outputs": [],
   "source": [
    "# Create new enhanced agent\n",
    "enhanced_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=enhanced_tools,\n",
    "    llm=Settings.llm,\n",
    "    system_prompt=\"\"\"You are an AI research assistant with access to:\n",
    "    1. The McKinsey 2025 State of AI report\n",
    "    2. Web search capabilities\n",
    "    3. ArXiv research paper search\n",
    "\n",
    "    Use these tools to provide comprehensive, well-researched answers. When discussing AI trends,\n",
    "    combine insights from the McKinsey report with recent research and web findings.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31wclWR0vWVJ"
   },
   "source": [
    "#### 2.16 Battle test agent with multiple questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvuCQ2GAoqmQ",
    "outputId": "3e0fb64c-3efe-4d8e-ed83-7d338f230f77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Organizational changes and governance\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking about specific changes companies are making for AI adoption, which requires retrieving specific context rather than summarization..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I encountered an issue while searching for recent research papers on AI governance. However, I found a recent research paper related to AI organizational transformation:\n",
      "\n",
      "- **Title:** Generalizing Verifiable Instruction Following\n",
      "- **Abstract:** This paper discusses the ability of language models or chatbots to follow human instructions precisely, focusing on output constraints. The study introduces a new benchmark, IFBench, to evaluate precise instruction following generalization on diverse and challenging verifiable out-of-domain constraints. The research also analyzes how models can be trained to improve precise instruction following generalization, emphasizing reinforcement learning with verifiable rewards.\n",
      "- **Link:** [Generalizing Verifiable Instruction Following](http://arxiv.org/pdf/2507.02833v1)\n",
      "\n",
      "For additional insights on AI governance and organizational transformation, I recommend exploring other sources or conducting a more specific search on AI governance research papers.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test questions that can benefit from multiple tools\n",
    "\n",
    "# Question 1: Combine McKinsey insights with recent research\n",
    "question1 = \"\"\"According to the McKinsey report, what are the main organizational changes companies are making for AI adoption?\n",
    "Can you also search for recent research papers on AI governance and organizational transformation to provide additional context?\"\"\"\n",
    "\n",
    "print(\"Question 1: Organizational changes and governance\")\n",
    "print(\"=\" * 50)\n",
    "response1 = await enhanced_agent.run(question1)\n",
    "print(response1)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-99uMZimpCXj",
    "outputId": "c368957f-5dc5-43ab-f1a7-6ccb8abddd86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2: Workflow Redesign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Workflow redesign for AI implementation would require retrieving specific context from the State of MFI Zeolite..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### McKinsey 2025 State of AI Report Insights on Workflow Redesign for AI Implementation:\n",
      "The McKinsey report emphasizes the importance of workflow redesign for successful AI implementation. It highlights that organizations need to rethink their processes to fully leverage the potential of AI technologies. Key points from the report include:\n",
      "\n",
      "1. **Process Optimization**: Organizations are advised to redesign workflows to optimize processes for AI integration, ensuring that AI systems can seamlessly interact with existing operations.\n",
      "\n",
      "2. **Skill Development**: The report suggests that companies should focus on upskilling employees to work alongside AI systems effectively, enabling a smooth transition in workflow redesign.\n",
      "\n",
      "3. **Change Management**: Managing change within the organization is crucial during workflow redesign for AI implementation. Companies need to address cultural shifts and ensure buy-in from all stakeholders.\n",
      "\n",
      "### ArXiv Papers on Business Process Automation with AI:\n",
      "1. **D3BA: A Tool for Optimizing Business Processes Using AI Planning**:\n",
      "   - This paper introduces D3BA, a tool for optimizing business processes through AI planning. It focuses on declarative design for digital business automation, enhancing complex processes with AI-powered optimization.\n",
      "\n",
      "2. **Can Artificial Intelligence Transform DevOps?**:\n",
      "   - The study explores the intersection of DevOps and AI, highlighting how AI can enhance DevOps practices such as testing, coding, release management, monitoring, and system improvement. It discusses the transformative potential of AI in DevOps.\n",
      "\n",
      "3. **Impact of Artificial Intelligence on Businesses**:\n",
      "   - This paper delves into the impact of AI on businesses, covering research, innovation, market deployment, and shifts in business models. It discusses the integration of AI into business processes and the implications for business strategies and models.\n",
      "\n",
      "### Web Articles on Workflow Transformation:\n",
      "Unfortunately, there was an issue retrieving web articles on workflow transformation. You may want to conduct a web search directly to explore recent articles on this topic for more insights.\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Workflow Redesign and Implementation\n",
    "question2 = \"\"\"What does the McKinsey report say about workflow redesign for AI implementation?\n",
    "Search ArXiv for papers on business process automation with AI and find current web articles about workflow transformation.\"\"\"\n",
    "\n",
    "print(\"Question 2: Workflow Redesign\")\n",
    "response2 = await enhanced_agent.run(question2)\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieLf-4v8qB8C",
    "outputId": "82c79861-d0f4-4b97-9e5a-c80058d5e5b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3: Risk management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking about specific risks organizations are addressing with gen AI, which requires retrieving specific context rather than summarization..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Recent Academic Research on AI Risk Mitigation:\n",
      "\n",
      "#### Web Search Results:\n",
      "- Unfortunately, there was an error retrieving web search results for recent academic research on AI risk mitigation.\n",
      "\n",
      "#### ArXiv Research Papers:\n",
      "1. **LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding**:\n",
      "   - This paper addresses the challenges in estimating treatment effects in medicine, particularly focusing on the bias introduced by inference time text confounding. The authors propose a framework that leverages large language models to mitigate biases caused by this confounding issue.\n",
      "\n",
      "2. **StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason**:\n",
      "   - The research introduces StepHint, an algorithm for reinforcement learning with verifiable rewards (RLVR) to enhance the reasoning abilities of large language models. StepHint utilizes multi-level stepwise hints to improve training efficiency and exploration in RLVR.\n",
      "\n",
      "3. **Generalizing Verifiable Instruction Following**:\n",
      "   - This study evaluates the ability of language models or chatbots to follow human instructions precisely, especially focusing on fulfilling verifiable output constraints. The authors introduce a new benchmark, IFBench, to assess precise instruction following generalization and propose reinforcement learning with verifiable rewards as a method to enhance instruction following.\n",
      "\n",
      "### Comparison with McKinsey Report:\n",
      "- The academic research papers focus on specific technical aspects of AI risk mitigation, such as bias in treatment effect estimation, reinforcement learning enhancements, and precise instruction following. These studies provide insights into mitigating risks associated with AI applications in healthcare, reasoning tasks, and language understanding.\n",
      "- In contrast, the McKinsey report highlights broader risks organizations face with gen AI, including hazards like friction, heat, and shock sensitivity, as well as concerns about the safe use of energetic compounds and detection of sensitive materials in security applications.\n",
      "- While the academic research delves into technical solutions for AI risk mitigation, the McKinsey report emphasizes practical challenges and safety considerations that organizations need to address when deploying gen AI technologies.\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Risk management and future trends\n",
    "question3 = \"\"\"Based on the McKinsey report, what are the key risks organizations are addressing with gen AI?\n",
    "Can you search the web for recent academic research on AI risk mitigation and compare with the report's findings?\"\"\"\n",
    "\n",
    "print(\"Question 3: Risk management\")\n",
    "response3 = await enhanced_agent.run(question3)\n",
    "print(response3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUIlpdi8qB5_",
    "outputId": "c0f08538-4edc-4af9-8553-4cd53fb315d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Comprehensive profile of Lareina Yee\n",
      "============================================================\n",
      "This question should force the agent to use:\n",
      "1. Query Engine - to find info about Lareina Yee in the McKinsey document\n",
      "2. Brave Search - to find recent web articles/news about her\n",
      "3. ArXiv Search - to find any academic papers she's authored\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking for specific information about 'Lareina Yee', which would require retrieving specific context rather than summarization..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Lareina Yee Profile:\n",
      "\n",
      "#### McKinsey 2025 State of AI Report:\n",
      "Lareina Yee is not mentioned in the McKinsey 2025 State of AI report.\n",
      "\n",
      "#### Web Search Insights:\n",
      "1. **Recent Articles and News:**\n",
      "   - No specific recent articles or news related to Lareina Yee's work on AI and workforce impact were found in the search results.\n",
      "\n",
      "#### ArXiv Research Papers Authored or Co-Authored by Lareina Yee:\n",
      "1. **Refinement of Partition Identities:**  \n",
      "   - Title: Refinement of some partition identities of Merca and Yee\n",
      "   - Summary: Merca and Yee proved partition identities involving new partition statistics. This paper refines these statistics, generalizes their results, and corrects a small mistake in a previous result.\n",
      "   - [Link to Paper](http://arxiv.org/pdf/2111.10587v1)\n",
      "\n",
      "2. **Combinatorial Proof of Identity:**  \n",
      "   - Title: Combinatorial proof of an identity of Andrews and Yee\n",
      "   - Summary: Andrews and Yee studied two-variable generalizations of partition functions introduced by Andrews, Dixit, and Yee. This paper presents a combinatorial proof of an interesting identity in their work.\n",
      "   - [Link to Paper](http://arxiv.org/pdf/1710.10373v2)\n",
      "\n",
      "3. **Identities Associated with Mock Theta Functions:**  \n",
      "   - Title: Some Identities associated with mock theta functions $\\omega(q)$ and $\\nu(q)$\n",
      "   - Summary: Andrews, Dixit, and Yee defined partition functions related to Ramanujan's mock theta functions. This paper presents two-variable generalizations of their results and reproves their results on these partition functions.\n",
      "   - [Link to Paper](http://arxiv.org/pdf/1709.03213v1)\n",
      "\n",
      "#### Comprehensive Profile:\n",
      "Lareina Yee's research work focuses on refining partition identities, providing combinatorial proofs of identities, and studying partition functions related to mock theta functions. Her contributions in these areas demonstrate a strong mathematical background and expertise in combinatorics and number theory. While her specific views on AI's workforce impact are not readily available, her research papers showcase a dedication to mathematical analysis and theoretical contributions in related fields.\n"
     ]
    }
   ],
   "source": [
    "# Question that forces usage of all three tools\n",
    "comprehensive_question = \"\"\"Who is Lareina Yee in the McKinsey document and what are her views on AI's workforce impact?\n",
    "\n",
    "After finding information about her from the document, please:\n",
    "1. Search the web using Brave Search for recent articles, interviews, or news about Lareina Yee and her work on AI\n",
    "2. Search ArXiv for any research papers she may have authored or co-authored related to AI, workforce transformation, or economic impact\n",
    "3. Provide a comprehensive profile combining insights from all three sources about her expertise and contributions to AI research\"\"\"\n",
    "\n",
    "print(\"Question: Comprehensive profile of Lareina Yee\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This question should force the agent to use:\")\n",
    "print(\"1. Query Engine - to find info about Lareina Yee in the McKinsey document\")\n",
    "print(\"2. Brave Search - to find recent web articles/news about her\")\n",
    "print(\"3. ArXiv Search - to find any academic papers she's authored\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = await enhanced_agent.run(comprehensive_question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3: ML in zeolite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Machine learning trend in Zeolite would require specific context and details, making choice 2 more relevant for retrieving such information..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n",
      "Failed to export batch code: 401, reason: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found some recent research papers related to machine learning trends in the context of 3D scene reconstruction and simulation, which may indirectly relate to Zeolite research. Here are a few papers that might provide insights into the application of machine learning in related fields:\n",
      "\n",
      "1. **Title:** MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real\n",
      "   - **Summary:** This work introduces MultiGen, a framework that integrates large-scale generative models into traditional physics simulators to enable multisensory simulation. The framework is showcased on the dynamic task of robot pouring, which relies on multimodal feedback.\n",
      "   - **Link:** [Read the Paper](http://arxiv.org/pdf/2507.02864v1)\n",
      "\n",
      "2. **Title:** Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory\n",
      "   - **Summary:** Point3R is an online framework for dense streaming 3D reconstruction that maintains an explicit spatial pointer memory associated with the 3D structure of the current scene. It achieves competitive performance on various tasks with low training costs.\n",
      "   - **Link:** [Read the Paper](http://arxiv.org/pdf/2507.02863v1)\n",
      "\n",
      "3. **Title:** LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans\n",
      "   - **Summary:** LiteReality is a pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. It supports key features essential for graphics pipelines and is suitable for applications in AR/VR, gaming, robotics, and digital twins.\n",
      "   - **Link:** [Read the Paper](http://arxiv.org/pdf/2507.02861v1)\n",
      "\n",
      "These papers may provide insights into the latest trends in machine learning applications for 3D scene reconstruction and simulation, which could be relevant to Zeolite research.\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Risk management and future trends\n",
    "question3 = \"\"\"What is the latest Machine learning trend that is apply to Zeolite?\"\"\"\n",
    "\n",
    "print(\"Question 3: ML in zeolite\")\n",
    "response3 = await enhanced_agent.run(question3)\n",
    "print(response3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb4e3fddbf47aaa90438c34a3aa0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_83d0691dc83e4b9683bbc0d75681e1cf",
      "style": "IPY_MODEL_7667a19e19894549b60ed2f2444fa1e9",
      "value": true
     }
    },
    "0de60d5681bf4ef9899bf3d25bb0cc7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41e4aad7ab7849c482b76b63e05c5103",
      "placeholder": "​",
      "style": "IPY_MODEL_90b457ea50244a4ebe9539792e8d144f",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "1408f43fc61b45f4978287227ae228d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d953736b2b7480d93cd4ba5ee083612": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5106674d1e8445418d5ac8b8a47236da",
      "placeholder": "​",
      "style": "IPY_MODEL_a01f8a252e944911b7f48a9bd7c38d77",
      "value": ""
     }
    },
    "2d67efd367d740c58603a4c2cff97043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83cce3969a774ce5b957bc1e8b9067c3",
      "placeholder": "​",
      "style": "IPY_MODEL_1408f43fc61b45f4978287227ae228d0",
      "value": "Connecting..."
     }
    },
    "41e4aad7ab7849c482b76b63e05c5103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5106674d1e8445418d5ac8b8a47236da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "535500bd04794bd085ac26f7d3ca8641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "604e4d2cccf54525923376a4d2c9030d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "7667a19e19894549b60ed2f2444fa1e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83cce3969a774ce5b957bc1e8b9067c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83d0691dc83e4b9683bbc0d75681e1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ea897cd11045d2a6e9499e1f376cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8de4f42760c84893ba42a6c21805aaed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "90b457ea50244a4ebe9539792e8d144f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a01f8a252e944911b7f48a9bd7c38d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c91f271675064f2199990457b8bee6d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d309591be2c74ec89237d7dc8cc2d35b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_8de4f42760c84893ba42a6c21805aaed"
     }
    },
    "d916a7725a754b0c97195dda0f81eb0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c91f271675064f2199990457b8bee6d2",
      "placeholder": "​",
      "style": "IPY_MODEL_87ea897cd11045d2a6e9499e1f376cba",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "f6d6c42ff8aa4267aae810403c3bc472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_535500bd04794bd085ac26f7d3ca8641",
      "style": "IPY_MODEL_604e4d2cccf54525923376a4d2c9030d",
      "tooltip": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
